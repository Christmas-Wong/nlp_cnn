# -*- coding: utf-8 -*-
"""
@Time       : 2022/1/19 5:35 下午
@Author     : Wang Fei
@Last Editor: Wang Fei
@Project    : template
@File       : args.py
@Software   : PyCharm
@Description:

    Define the Classes for Training process and Text_CNN model

"""
from torch import Tensor
from dataclasses import dataclass, field


@dataclass
class TrainingArguments:
    """
        TrainingArguments is the Arguments for Training Process

    :parameter
        dir_output (:obj:`str`, `optional`):
            Dir where your output file will be saved
        train_file: Train Dataset
        test_file: Test Dataset
        eval_file: Evaluation Dataset
        learning_rate (:obj:float, `optional`, defaults to 1e-5):
            The initial learning rate for optimizer
        train_batch_size (:obj:`int`, `optional`, defaults to 8):
            The batch size per GPU for training
        eval_batch_size (:obj:`int`, `optional`, defaults to 8):
            The batch size per GPU for training
        num_train_epoch (:obj:`float`, `optional`, defaults to 20):
            Total number of training epochs to perform
        early_stopping (:obj:`int`, `optional`, defaults to 5):
            The patience of early stopping
        early_stopping (:obj:`int`, `optional`, defaults to 0):
            Evaluate Model when training for n steps
            If :obj:0, Evaluate Model for every batch
            if :obj:n, Evaluate Model for every n step
    """
    dir_output: str = field(
        metadata={"help": "The output directory where the model predictions and checkpoints will be written."},
    )
    train_file: str = field(
        metadata={"help": "Train File"}
    )
    test_file: str = field(
        metadata={"help": "Test File"}
    )
    eval_file: str = field(
        metadata={"help": "Eval File"}
    )
    learning_rate: float = field(
        default=1e-5,
        metadata={"help": "Learning Rate"}
    )
    train_batch_size: int = field(
        default=16,
        metadata={"help": "Train Batch Size"}
    )
    eval_batch_size: int = field(
        default=16,
        metadata={"help": "Eval Batch Size"}
    )
    num_train_epoch: int = field(
        default=20,
        metadata={"help": "Number of Train Epoch"}
    )
    early_stopping: int = field(
        default=5,
        metadata={"help": "Patience of Early Stopping"}
    )
    eval_step: int = field(
        default=0,
        metadata={"help": "Evaluate Model when training n steps"}
    )


@dataclass
class TextCNNArguments:
    """
    TextCNNArguments is the hyper parameters of TextCNN that we need to be defined

    Parameter:
        vocab_size (:obj:`int`, `optional`):
            The number of words in vocab
        embedding_pretrained (:obj:`Tensor`, `optional`, defaults to :obj:`None`):
            Pretrained embedding tensor generated by word2vec or glove
            If :obj:`None`, Initial the embedding layer of model randomly
            If :obj: `Tensor`, Initial the embedding layer of model with pretrained embedding tensor
        filters (:obj `list`):
            List of Convolutional Kernel size
        number_labels (:obj:`int`, `optional`):
            The number of different labels
        embedding (:obj:`tensor`, `optional`):
            Pretrained embedding tensor generated by word2vec or glove
            If :obj:`None`, Initial the embedding layer of model randomly
            If :obj: `Tensor`, Initial the embedding layer of model with pretrained embedding tensor
        embedding_type (:obj:`str`, `optional`, defaults to :obj: `random`):
            The
    """
    vocab_size: int = field(
        metadata={"help": "Size of Vocabulary"}
    )
    embedding_dim: int = field(
        metadata={"help": "Dim of Embedding"}
    )
    num_labels: int = field(
        metadata={"help": "Number of labels"}
    )
    embedding: Tensor = field(
        metadata={"help": "Embedding Layer"}
    )
    embedding_type: str = field(
        default="random",
        metadata={"help": "Embedding Type"}
    )
    filters: list = field(
        default_factory=list
    )
    num_filters: list = field(
        default_factory=list
    )
    dropout: float = field(
        default=0.5,
        metadata={"help": "Probability of Dropout"}
    )


@dataclass
class DPCNNArguments:
    """
    TextCNNArguments is the hyper parameters of TextCNN that we need to be defined

    Parameter:
        vocab_size (:obj:`int`, `optional`):
            The number of words in vocab
        embedding_pretrained (:obj:`Tensor`, `optional`, defaults to :obj:`None`):
            Pretrained embedding tensor generated by word2vec or glove
            If :obj:`None`, Initial the embedding layer of model randomly
            If :obj: `Tensor`, Initial the embedding layer of model with pretrained embedding tensor
        filters (:obj `list`):
            List of Convolutional Kernel size
        number_labels (:obj:`int`, `optional`):
            The number of different labels
        embedding (:obj:`tensor`, `optional`):
            Pretrained embedding tensor generated by word2vec or glove
            If :obj:`None`, Initial the embedding layer of model randomly
            If :obj: `Tensor`, Initial the embedding layer of model with pretrained embedding tensor
        embedding_type (:obj:`str`, `optional`, defaults to :obj: `random`):
            The
    """
    vocab_size: int = field(
        metadata={"help": "Size of Vocabulary"}
    )
    embedding_dim: int = field(
        metadata={"help": "Dim of Embedding"}
    )
    num_labels: int = field(
        metadata={"help": "Number of labels"}
    )
    embedding: Tensor = field(
        metadata={"help": "Embedding Layer"}
    )
    embedding_type: str = field(
        default="random",
        metadata={"help": "Embedding Type"}
    )
    num_filters: int = field(
        default=250,
        metadata={"help": "Number of Filters"}
    )
    dropout: float = field(
        default=0.5,
        metadata={"help": "Probability of Dropout"}
    )


